{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UnNLI.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNdmGJ+JTvlSheXS/Eq+HwC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Masoud-Karami/Abstracts/blob/main/UnNLI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hFs4MkCYGaU"
      },
      "source": [
        "#**[UnNLI](https://arxiv.org/abs/2101.00010)** \n",
        "UnNatural Language Inference\n",
        " [code](https://github.com/facebookresearch/unlu)\n",
        "\n",
        "[requirement](https://github.com/facebookresearch/unlu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3d1MODNY5Yj"
      },
      "source": [
        ">## NLU\n",
        ">><ol>\n",
        "        <li><i><b>Generalizability of the NLI framework:</i></b> nearly all questions about meaningfulness in language can be reduced to questions of entailment and contradiction in context</li>\n",
        "        <li><i><b>Permutation-free models:</i></b> state-of-the-art Natural Language Inference (NLI) models are largely invariant to random word-order permutations</li>\n",
        "        <li><i><b>Syntax:</i></b> knowing the syntax of a sentence means being sensitive to the order of the words in that sentence, i.e <i>''language is not merely a bag of words''</i></li>\n",
        "        <li><i><b>sentence superiority effect:</i></b> it is easier for us to identify or recall words presented in canonical orders than in disordered, ungrammatical sentences.</li>\n",
        "        <li><i><b>words v.s word orders:</i></b> NLI models focus on words more than word order, but can partially reconstruct syntactic information from words alone.\n",
        "        <li><i><b>Textual entailment:</i></b> also called <b>Natural Language Inference (NLI)</b>, is one of the task used to measure how well models understand language consists of two sentences:\n",
        "                <ul>\n",
        "                    <li> premise</li>\n",
        "                    <li> hypothesis</li>\n",
        "                </ul>\n",
        "        <li><i><b>Meaning: human vs machine:</i></b> linguists generally take syntactic structure to be necessary for humans to know what sentences mean.\n",
        "        <li><i><b>Truth-conditional in propositional logic:</i></b> understanding a sentence is equivalent to knowing the actual conditions of the world under which the sentences would be (judged) true.\n",
        "        <li><i><b>Truth-conditional in propositional logic:</i></b> the meanings (if they exist) of highly permuted sentences are not propositions, and thus those sentences don’t have truth conditions. Only from their truth conditions of sentences can we tell if a sentence entails another.\n",
        "        <li><i><b>hypothetical systematic performances:</i></b> \n",
        "                <ul>\n",
        "                    <li> models that operate on the first principles of NLI</li>\n",
        "                            <ul type='square'>\n",
        "                                    <li>  Model A which thinks permuted sentences are meaningless. It assigns “neutral” to every permuted</li>\n",
        "                                    <li>  Model B which does not deem permuted sentences meaningless, and attempts to understand them</li>\n",
        "                            </ul>\n",
        "                    <li> non-systematic model, Model C, which attempts to treat permuted sentences as though they weren’t permuted at all. Could operate similarly as bag-of-words (BOW), and thus always assign the same label to the permuted examples as\n",
        "it would to the un-permuted examples</li>\n",
        "                </ul>\n",
        "        <li><i><b>Permutation acceptance metrics:</i></b> enable us to quantify how accepting models are of permuted sentences.\n",
        "        </ol>\n",
        "         "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1hVOvI8i42t"
      },
      "source": [
        "##Method:\n",
        "1. <b>Constructing the permuted dataset</b>\n",
        "    * dataset $D$ having splits $D_{train}$ and $D_{test}$,\n",
        "    * train an NLI model $M$ on $D_{\\text{train}}$ to achieve comparable accuracy (baseline)\n",
        "    * construct a randomized version of $D_{\\text{test}}$ as $\\hat{D}_{\\text{test}}$\n",
        "   <ul>\n",
        "        <li>for each example $(p_i,h_i,y_i) \\in D_{\\text{test}}$ ($p_i$ and $h_i$ are the **premise** and **hypothesis** sentences of the example respectively and $y_i$ is the $\\href{https://stats.stackexchange.com/questions/333446/what-does-the-term-gold-label-refer-to-in-the-context-of-semi-supervised-class}{gold}$ label which represents some reliable ground-truth value), we use a permutation operator $\\mathcal{F}$ that returns a list ($\\hat{P}_i, \\hat{H}_i$) of $q$ permuted sentences ($\\hat{p}_i$ and $\\hat{h}_i$), where $q$ is a hyperparameter.\n",
        "        </li>\n",
        "        <li>$$\\forall(p_i,h_i,y_i) \\in D_{\\text{test}}: \\mathcal{F}(p_i,h_i,y_i)=\\{(\\hat{p}_{1i} \\hat{h}_{1i}), ..., (\\hat{p}_{qi} \\hat{h}_{qi})\\}=(\\hat{P}_i, \\hat{H}_i)$$\n",
        "        *no words maintain their original position*\n",
        "        </li>\n",
        "        <li>$\\hat{D}_{\\text{test}}$ now consists of $|D_{\\text{test}}| \\times q$ examples with $q$ different permutations,</li>\n",
        "        <li>total number of available permutations of sentence $S, |S|=w$, are $(w-1)!$</li>\n",
        "        <li>output norm of the $\\mathcal{F}$ is then $(w-1)! \\choose q$</li>\n",
        "        <li>permute $p_i$ and $h_i$ separately</li>\n",
        "   </ul>\n",
        "\n",
        "   * $\\Omega_{x} = \\frac{1}{\\mid D_{test}\\mid} \\sum_{{(p_i, h_i)\\in D_{test}}} ((\\Pr_{M}(\\hat{P}_i, \\hat{H}_i)_{\\text{cor}}> x)\\rightarrow 1),$\n",
        "   * $\\Omega_{\\text{max}}$ or the <b>Maximum Accuracy</b>, where $x = 1 / |D_{\\text{test}}|$\n",
        "   * \n",
        "\n",
        "2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iW7pyXfY6F3"
      },
      "source": [
        "##[demo](https://colab.research.google.com/drive/1vv8Xmag1go3dib4vZXUZXAFB4ltDaMH7?usp=sharing#scrollTo=MQPQU6YTIkab)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEnxPPcBY_qN"
      },
      "source": [
        "!pip install omegaconf\n",
        "!pip install hydra-core --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqQCedjZZJUB"
      },
      "source": [
        "import torch\n",
        "model = torch.hub.load('pytorch/fairseq', 'roberta.large.mnli')\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}