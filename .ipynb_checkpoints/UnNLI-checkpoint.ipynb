{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Masoud-Karami/Abstracts/blob/main/UnNLI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2hFs4MkCYGaU"
   },
   "source": [
    "<h1><a href=https://arxiv.org/abs/2101.00010>UnNatural Language Inference (UnNLI)</a></h1>\n",
    "\n",
    "   - [code](https://github.com/facebookresearch/unlu)\n",
    "\n",
    "   - [requirement](https://github.com/facebookresearch/unlu)\n",
    "\n",
    "   - [Youtube Presentation](https://www.youtube.com/watch?v=oAM0Sr1WNW0&ab_channel=KoustuvSinha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3d1MODNY5Yj"
   },
   "source": [
    ">## NLU\n",
    "><ol>\n",
    "        <li><i><b>Generalizability of the NLI framework:</i></b> nearly all questions about meaningfulness in language can be reduced to questions of entailment and contradiction in context</li>\n",
    "        <li><i><b>Permutation-free models:</i></b> state-of-the-art Natural Language Inference (NLI) models are largely invariant to random word-order permutations</li>\n",
    "        <li><i><b>Syntax:</i></b> knowing the syntax of a sentence means being sensitive to the order of the words in that sentence, i.e <i>''language is not merely a bag of words''</i></li>\n",
    "        <li><i><b>sentence superiority effect:</i></b> it is easier for us to identify or recall words presented in canonical orders than in disordered, ungrammatical sentences.</li>\n",
    "        <li><i><b>words v.s word orders:</i></b> NLI models focus on words more than word order, but can partially reconstruct syntactic information from words alone.\n",
    "        <li><i><b>Textual entailment:</i></b> also called <b>Natural Language Inference (NLI)</b>, is one of the task used to measure how well models understand language consists of two sentences:\n",
    "                <ul>\n",
    "                    <li> premise</li>\n",
    "                    <li> hypothesis</li>\n",
    "                </ul>\n",
    "        <li><i><b>Meaning: human vs machine:</i></b> linguists generally take syntactic structure to be necessary for humans to know what sentences mean.\n",
    "        <li><i><b>Truth-conditional in propositional logic:</i></b> understanding a sentence is equivalent to knowing the actual conditions of the world under which the sentences would be (judged) true.Truth-conditional theories of semantics attempt to define the meaning of a given proposition by explaining when the sentence is true. So, for example, because <code><mark>snow is white</mark></code> is true iff snow is white, the meaning of <code><mark>snow is white</mark></code> is snow is white.\n",
    "        <li><i><b>hypothetical systematic performances:</i></b> \n",
    "                <ul>\n",
    "                    <li> models that operate on the first principles of NLI</li>\n",
    "                            <ul type='square'>\n",
    "                                    <li>  Model A which thinks permuted sentences are meaningless. It assigns “neutral” to every permuted</li>\n",
    "                                    <li>  Model B which does not deem permuted sentences meaningless, and attempts to understand them</li>\n",
    "                            </ul>\n",
    "                    <li> non-systematic model, Model C, which attempts to treat permuted sentences as though they weren’t permuted at all. Could operate similarly as bag-of-words (BOW), and thus always assign the same label to the permuted examples as\n",
    "it would to the un-permuted examples</li>\n",
    "                </ul>\n",
    "        <li><i><b>Permutation acceptance metrics:</i></b> enable us to quantify how accepting models are of permuted sentences.\n",
    "        </ol>\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1hVOvI8i42t"
   },
   "source": [
    ">## Method:\n",
    ">1. <b>Constructing the permuted dataset</b>\n",
    "    * dataset $D$ having splits $D_{train}$ and $D_{test}$,\n",
    "    * train an NLI model $M$ on $D_{\\text{train}}$ to achieve comparable accuracy (baseline)\n",
    "    * construct a randomized version of $D_{\\text{test}}$ as $\\hat{D}_{\\text{test}}$\n",
    "   <ul>\n",
    "        <li>for each example $(p_i,h_i,y_i) \\in D_{\\text{test}}$ ($p_i$ and $h_i$ are the **premise** and **hypothesis** sentences of the example respectively and $y_i$ is the $\\href{https://stats.stackexchange.com/questions/333446/what-does-the-term-gold-label-refer-to-in-the-context-of-semi-supervised-class}{gold}$ label which represents some reliable ground-truth value), we use a permutation operator $\\mathcal{F}$ that returns a list ($\\hat{P}_i, \\hat{H}_i$) of $q$ permuted sentences ($\\hat{p}_i$ and $\\hat{h}_i$), where $q$ is a hyperparameter.\n",
    "        </li>\n",
    "        <li>$$\\forall(p_i,h_i,y_i) \\in D_{\\text{test}}: \\mathcal{F}(p_i,h_i,y_i)=\\{(\\hat{p}_{1i} \\hat{h}_{1i}), ..., (\\hat{p}_{qi} \\hat{h}_{qi})\\}=(\\hat{P}_i, \\hat{H}_i)$$\n",
    "        *no words maintain their original position*\n",
    "        </li>\n",
    "        <li>$\\hat{D}_{\\text{test}}$ now consists of $|D_{\\text{test}}| \\times q$ examples with $q$ different permutations,</li>\n",
    "        <li>total number of available permutations of sentence $S, |S|=w$, are $(w-1)!$</li>\n",
    "        <li>output norm of the $\\mathcal{F}$ is then $(w-1)! \\choose q$</li>\n",
    "        <li>permute $p_i$ and $h_i$ separately</li>\n",
    "   </ul>\n",
    ">\n",
    ">   * $x$ is a predetermind threshold for the percentage $Pr()$ belongs to $0<x<1$\n",
    ">\n",
    ">   * $\\Omega_{x} = \\frac{1}{\\mid D_{test}\\mid} \\sum_{{(p_i, h_i)\\in D_{test}}} ((\\Pr_{M}(\\hat{P}_i, \\hat{H}_i)_{\\text{cor}}> x)\\rightarrow 1),$\n",
    "   * $\\Omega_{\\text{max}}$ or the <b>Maximum Accuracy</b>, where $x = 1 / |D_{\\text{test}}|$\n",
    "        - there is $\\textit{at least one}$ permutation $(\\hat{p_j}, \\hat{h_j})$ that model $M$ assigns the gold label $y_i$,\n",
    "   * <b>Random Baseline Accuracy</b>, where $x = 1 / m$ or chance probability (for balanced $m$-way classification, where $m=3$ in NLI).\n",
    "        - This metric is less stringent than $\\Omega_{\\text{max}}$\n",
    "   * In a model with high accuracy $D^f < D^c$ which $D^f$ is flipped examples (`examples originally marked incorrect according to `$\\mathcal{A}$, `but are now deemed correct according `$\\Omega_{\\text{max}}$) and $D^c$ the examples originally marked correct\n",
    ">\n",
    ">2. <b>Analysis and findins</b>\n",
    "    - This shows that there exists at least one permutation (usually many more) for almost all examples in $D_{\\text{test}}$ such that model $M$ predicts the gold label.\n",
    "    * there are many examples for which the models outperform even a random baseline in accepting permuted sentences. $\\mathcal{A}$ is given by $\\frac{c}{|D_{test}|}$ or $\\frac{c}{|D_{dev}|}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1iW7pyXfY6F3"
   },
   "source": [
    "##[demo](https://colab.research.google.com/drive/1vv8Xmag1go3dib4vZXUZXAFB4ltDaMH7?usp=sharing#scrollTo=MQPQU6YTIkab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XEnxPPcBY_qN"
   },
   "outputs": [],
   "source": [
    "!pip install omegaconf\n",
    "!pip install hydra-core --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fqQCedjZZJUB"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/fairseq', 'roberta.large.mnli')\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOLEb01Nj6cPvvsQrAxp/SI",
   "include_colab_link": true,
   "name": "UnNLI.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
