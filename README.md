<h1> Interpretable NLP model and XAI</h1>

<h2>More specifically the sensitivity of neural NLP models on perturbed input text</h2>

<ol>
        <li><a href=https://arxiv.org/abs/2108.04840>Post-hoc Interpretability for Neural NLP: A Survey</a></li>
        <li> <a href=https://arxiv.org/abs/2107.13955>Demystifying Neural Language Modelsâ€™ Insensitivity to Word-Order</a>
        </li>
        <li><a href=https://arxiv.org/abs/2101.00010>UnNatural Language Inference (UnNLI)</a></li>
        <li><a href=https://arxiv.org/abs/2101.03453>BERT & Family Eat Word Salad: Experiments with Text Understanding</a></li>
        <li><a href=https://arxiv.org/abs/1909.09595>Visual Analytics for Understanding Self-Attention Networks (SANVis)</a></li>
        <li><a href=https://arxiv.org/abs/1906.05714> BERTViz: A Multiscale Visualization of Attention in the Transformer Model</a></li>
        <li></li>
</ol>
